/* ###### AutoGenerated File. Generated Data:Thu Jul 09 20:36:55 EEST 2020 ###### */

#ifndef __OPENCL_CL_FILES_H__
#define __OPENCL_CL_FILES_H__

#include <stddef.h>

static const char *CL_OCLMATVECMUL[] = { 
	"/*\n",
	" * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
	" *\n",
	" * Please refer to the NVIDIA end user license agreement (EULA) associated\n",
	" * with this source code for terms and conditions that govern your use of\n",
	" * this software. Any use, reproduction, disclosure, or distribution of\n",
	" * this software and related documentation outside the terms of the EULA\n",
	" * is strictly prohibited.\n",
	" *\n",
	" */\n",
	" \n",
	"/* Matrix-vector multiplication: W = M * V.\n",
	" * Device code.\n",
	" *\n",
	" * This sample implements matrix-vector multiplication.\n",
	" * It has been written for clarity of exposition to illustrate various OpenCL\n",
	" * programming principles and optimizatoins, not with the goal of providing\n",
	" * the most performant generic kernel for matrix-vector multiplication.\n",
	" *\n",
	" * CUBLAS provides high-performance matrix-vector multiplication on GPU.\n",
	" */\n",
	" \n",
	"// Matrix multiplication kernel called by MatrixMul()\n",
	"__kernel void MatVecMulUncoalesced0(const __global float* M,\n",
	"                                    const __global float* V,\n",
	"                                    uint width, uint height,\n",
	"                                    __global float* W)\n",
	"{\n",
	"    // Row index\n",
	"    uint y = get_global_id(0);\n",
	"    if (y < height) {\n",
	"    \n",
	"        // Row pointer\n",
	"        const __global float* row = M + y * width;\n",
	"\n",
	"        // Compute dot product  \n",
	"        float dotProduct = 0;\n",
	"        for (int x = 0; x < width; ++x)\n",
	"            dotProduct += row[x] * V[x];\n",
	"\n",
	"        // Write result to global memory\n",
	"        W[y] = dotProduct;\n",
	"    }\n",
	"}\n",
	"\n",
	"// Matrix multiplication kernel called by MatrixMul()\n",
	"__kernel void MatVecMulUncoalesced1(const __global float* M,\n",
	"                                    const __global float* V,\n",
	"                                    uint width, uint height,\n",
	"                                    __global float* W)\n",
	"{        \n",
	"    // Each work-item handles as many matrix rows as necessary\n",
	"    for (uint y = get_global_id(0);\n",
	"         y < height;\n",
	"         y += get_global_size(0))\n",
	"    {\n",
	"\n",
	"        // Row pointer\n",
	"        const __global float* row = M + y * width;\n",
	"\n",
	"        // Compute dot product  \n",
	"        float dotProduct = 0;\n",
	"        for (uint x = 0; x < width; ++x)\n",
	"            dotProduct += row[x] * V[x];\n",
	"\n",
	"        // Write result to global memory\n",
	"        W[y] = dotProduct;\n",
	"    }\n",
	"}\n",
	"\n",
	"// Matrix multiplication kernel called by MatrixMul()\n",
	"__kernel void MatVecMulCoalesced0(const __global float* M,\n",
	"                                  const __global float* V,\n",
	"                                  uint width, uint height,\n",
	"                                  __global float* W,\n",
	"                                  __local float* partialDotProduct)\n",
	"{    \n",
	"    // Each work-group handles as many matrix rows as necessary\n",
	"    for (uint y = get_group_id(0); y < height; y += get_num_groups(0)) {\n",
	"\n",
	"        // Row pointer\n",
	"        const __global float* row = M + y * width;\n",
	"        \n",
	"        // Each work-item accumulates as many products as necessary\n",
	"        // into local variable \"sum\"\n",
	"        float sum = 0;\n",
	"        for (uint x = get_local_id(0); x < width; x += get_local_size(0))\n",
	"            sum += row[x] * V[x];\n",
	"\n",
	"        // Each partial dot product is stored in shared memory\n",
	"        partialDotProduct[get_local_id(0)] = sum;\n",
	"\n",
	"        // Synchronize to make sure each work-item is done updating\n",
	"        // shared memory; this is necessary because in the next step,\n",
	"        // the first work-item needs to read from shared memory\n",
	"        // the partial dot products written by the other work-items\n",
	"        barrier(CLK_LOCAL_MEM_FENCE);\n",
	"\n",
	"        // The first work-item in the work-group adds all partial\n",
	"        // dot products together and writes the result to global memory\n",
	"        if (get_local_id(0) == 0) {\n",
	"            float dotProduct = 0;\n",
	"            for (uint t = 0; t < get_local_size(0); ++t)\n",
	"                dotProduct += partialDotProduct[t];\n",
	"            W[y] = dotProduct;\n",
	"	    }\n",
	"\n",
	"        // Synchronize to make sure the first work-item is done with\n",
	"        // reading partialDotProduct\n",
	"        barrier(CLK_LOCAL_MEM_FENCE);\n",
	"	}\n",
	"}\n",
	"\n",
	"// Matrix multiplication kernel called by MatrixMul()\n",
	"__kernel void MatVecMulCoalesced1(const __global float* M,\n",
	"                                  const __global float* V,\n",
	"                                  uint width, uint height,\n",
	"                                  __global float* W,\n",
	"                                  __local float* partialDotProduct)\n",
	"{    \n",
	"    // Each work-group handles as many matrix rows as necessary\n",
	"    for (uint y = get_group_id(0); y < height; y += get_num_groups(0)) {\n",
	"\n",
	"        // Row pointer\n",
	"        const __global float* row = M + y * width;\n",
	"        \n",
	"        // Each work-item accumulates as many products as necessary\n",
	"        // into local variable \"sum\"\n",
	"        float sum = 0;\n",
	"        for (uint x = get_local_id(0); x < width; x += get_local_size(0))\n",
	"            sum += row[x] * V[x];\n",
	"\n",
	"        // Each partial dot product is stored in shared memory\n",
	"        partialDotProduct[get_local_id(0)] = sum;\n",
	"        \n",
	"        // Perform parallel reduction to add each work-item's\n",
	"        // partial dot product together\n",
	"        for (uint stride = 1; stride < get_local_size(0); stride *= 2) {\n",
	"\n",
	"            // Synchronize to make sure each work-item is done updating\n",
	"            // shared memory; this is necessary because work-items read\n",
	"            // results that have been written by other work-items\n",
	"            barrier(CLK_LOCAL_MEM_FENCE);\n",
	"            \n",
	"            // Index into the \"partialDotProduct\" array where\n",
	"            // the work-item will write during this step\n",
	"            uint index = 2 * stride * get_local_id(0);\n",
	"            \n",
	"            // Check for valid indices\n",
	"            if (index < get_local_size(0)) {\n",
	"            \n",
	"                // Add two elements from the \"partialDotProduct\" array\n",
	"                // and store the result in partialDotProduct[index]\n",
	"                partialDotProduct[index] += partialDotProduct[index + stride];\n",
	"            }\n",
	"        }\n",
	"\n",
	"        // Write the result of the reduction to global memory\n",
	"        if (get_local_id(0) == 0)\n",
	"            W[y] = partialDotProduct[0];\n",
	"\n",
	"        // Synchronize to make sure the first work-item is done with\n",
	"        // reading partialDotProduct\n",
	"        barrier(CLK_LOCAL_MEM_FENCE);\n",
	"    }\n",
	"}\n",
	"\n",
	"// Matrix multiplication kernel called by MatrixMul()\n",
	"__kernel void MatVecMulCoalesced2(const __global float* M,\n",
	"                                  const __global float* V,\n",
	"                                  uint width, uint height,\n",
	"                                  __global float* W,\n",
	"                                  __local float* partialDotProduct)\n",
	"{    \n",
	"    // Each work-group handles as many matrix rows as necessary\n",
	"    for (uint y = get_group_id(0); y < height; y += get_num_groups(0)) {\n",
	"\n",
	"        // Row pointer\n",
	"        const __global float* row = M + y * width;\n",
	"        \n",
	"        // Each work-item accumulates as many products as necessary\n",
	"        // into local variable \"sum\"\n",
	"        float sum = 0;\n",
	"        for (uint x = get_local_id(0); x < width; x += get_local_size(0))\n",
	"            sum += row[x] * V[x];\n",
	"\n",
	"        // Each partial dot product is stored in shared memory\n",
	"        partialDotProduct[get_local_id(0)] = sum;\n",
	"        \n",
	"        // Perform parallel reduction to add each work-item's\n",
	"        // partial dot product together\n",
	"        for (uint stride = get_local_size(0) / 2; stride > 0; stride /= 2) {\n",
	"\n",
	"            // Synchronize to make sure each work-item is done updating\n",
	"            // shared memory; this is necessary because work-items read\n",
	"            // results that have been written by other work-items\n",
	"            barrier(CLK_LOCAL_MEM_FENCE);\n",
	"            \n",
	"            // Only the first work-items in the work-group add elements together\n",
	"            if (get_local_id(0) < stride) {\n",
	"            \n",
	"                // Add two elements from the \"partialDotProduct\" array\n",
	"                // and store the result in partialDotProduct[index]\n",
	"                partialDotProduct[get_local_id(0)] += partialDotProduct[get_local_id(0) + stride];\n",
	"            }\n",
	"        }\n",
	"\n",
	"        // Write the result of the reduction to global memory\n",
	"        if (get_local_id(0) == 0)\n",
	"            W[y] = partialDotProduct[0];\n",
	"\n",
	"        // Synchronize to make sure the first work-item is done with\n",
	"        // reading partialDotProduct\n",
	"        barrier(CLK_LOCAL_MEM_FENCE);\n",
	"    }\n",
	"}\n",
	"\n",
	"#define WARP_SIZE 32\n",
	"__kernel void MatVecMulCoalesced3(const __global float* M,\n",
	"                                  const __global float* V,\n",
	"                                  uint width, uint height,\n",
	"                                  __global float* W,\n",
	"                                  __local float* partialDotProduct)\n",
	"{\n",
	"   // Each work-group computes multiple elements of W\n",
	"   for (uint y = get_group_id(0); y < height; y += get_num_groups(0)) {\n",
	"      const __global float* row = M + y * width;\n",
	"\n",
	"      // Each work-item accumulates as many products as necessary\n",
	"      // into local variable \"sum\"\n",
	"      float sum = 0;\n",
	"      for (uint x = get_local_id(0); x < width; x += get_local_size(0))\n",
	"         sum += row[x] * V[x];\n",
	"\n",
	"      // Each partial dot product is stored in shared memory\n",
	"      partialDotProduct[get_local_id(0)] = sum;\n",
	"\n",
	"      // Perform parallel reduction to add each work-item's\n",
	"      // partial dot product together\n",
	"\n",
	"      // Synchronize to make sure each work-item is done writing to\n",
	"      // partialDotProduct\n",
	"      barrier(CLK_LOCAL_MEM_FENCE);\n",
	"\n",
	"      // Thread local ID within a warp\n",
	"      uint id = get_local_id(0) & (WARP_SIZE - 1); \n",
	"\n",
	"      // Each warp reduces 64 consecutive elements\n",
	"      float warpResult = 0.0f;\n",
	"      if (get_local_id(0) < get_local_size(0)/2 )\n",
	"      {\n",
	"          volatile __local float* p = partialDotProduct + 2 * get_local_id(0) - id;\n",
	"          p[0] += p[32];\n",
	"          p[0] += p[16];\n",
	"          p[0] += p[8];\n",
	"          p[0] += p[4];\n",
	"          p[0] += p[2];\n",
	"          p[0] += p[1];\n",
	"          warpResult = p[0];\n",
	"      }\n",
	"\n",
	"      // Synchronize to make sure each warp is done reading\n",
	"      // partialDotProduct before it is overwritten in the next step\n",
	"      barrier(CLK_LOCAL_MEM_FENCE);\n",
	"\n",
	"      // The first thread of each warp stores the result of the reduction\n",
	"      // at the beginning of partialDotProduct\n",
	"      if (id == 0)\n",
	"         partialDotProduct[get_local_id(0) / WARP_SIZE] = warpResult;\n",
	"\n",
	"      // Synchronize to make sure each warp is done writing to\n",
	"      // partialDotProduct before it is read in the next step\n",
	"      barrier(CLK_LOCAL_MEM_FENCE);\n",
	"\n",
	"      // Number of remaining elements after the first reduction\n",
	"      uint size = get_local_size(0) / (2 * WARP_SIZE);\n",
	"\n",
	"      // get_local_size(0) is less or equal to 512 on NVIDIA GPUs, so\n",
	"      // only a single warp is needed for the following last reduction\n",
	"      // step\n",
	"      if (get_local_id(0) < size / 2) {\n",
	"         volatile __local float* p = partialDotProduct + get_local_id(0);\n",
	"         if (size >= 8)\n",
	"            p[0] += p[4];\n",
	"         if (size >= 4)\n",
	"            p[0] += p[2];\n",
	"         if (size >= 2)\n",
	"            p[0] += p[1];\n",
	"      }\n",
	"\n",
	"      // Write the result of the reduction to global memory\n",
	"      if (get_local_id(0) == 0)\n",
	"         W[y] = partialDotProduct[0];\n",
	"\n",
	"      // Synchronize to make sure the first work-item is done with\n",
	"      // reading partialDotProduct\n",
	"      barrier(CLK_LOCAL_MEM_FENCE);\n",
	"   }\n",
	"}\n",
	""};


static const size_t CL_OCLMATVECMUL_SIZE = sizeof(CL_OCLMATVECMUL) / sizeof(const char *);


static const char *CL_TST_KERNELS[] = { 
	"__kernel void sobel_filter_color(__read_only image2d_t inputImage,\n",
	"                              __write_only image2d_t outputImage,\n",
	"                              int width, int height)\n",
	"{\n",
	"\n",
	"	int2 coord = (int2)(get_global_id(0), get_global_id(1));\n",
	"\n",
	"	float4 Gx = (float4)(0);\n",
	"	float4 Gy = Gx;\n",
	"\n",
	"	constant sampler_t imageSampler = CLK_NORMALIZED_COORDS_FALSE | CLK_ADDRESS_CLAMP | CLK_FILTER_LINEAR;\n",
	"\n",
	"\n",
	"	if( coord.x >= 1 && coord.x < (get_global_size(0)-1) && coord.y >= 1 && coord.y < get_global_size(1) - 1)\n",
	"	{\n",
	"		float4 i00 = convert_float4(read_imagef(inputImage, imageSampler, (int2)(coord.x - 1, coord.y + 1)));\n",
	"		float4 i10 = convert_float4(read_imagef(inputImage, imageSampler, (int2)(coord.x - 0, coord.y + 1)));\n",
	"		float4 i20 = convert_float4(read_imagef(inputImage, imageSampler, (int2)(coord.x + 1, coord.y + 1)));\n",
	"		float4 i01 = convert_float4(read_imagef(inputImage, imageSampler, (int2)(coord.x - 1, coord.y + 0)));\n",
	"		float4 i11 = convert_float4(read_imagef(inputImage, imageSampler, (int2)(coord.x - 0, coord.y + 0)));\n",
	"		float4 i21 = convert_float4(read_imagef(inputImage, imageSampler, (int2)(coord.x + 1, coord.y + 0)));\n",
	"		float4 i02 = convert_float4(read_imagef(inputImage, imageSampler, (int2)(coord.x - 1, coord.y - 1)));\n",
	"		float4 i12 = convert_float4(read_imagef(inputImage, imageSampler, (int2)(coord.x - 0, coord.y - 1)));\n",
	"		float4 i22 = convert_float4(read_imagef(inputImage, imageSampler, (int2)(coord.x + 1, coord.y - 1)));\n",
	"\n",
	"		Gx =   i00 + (float4)(2) * i10 + i20 - i02  - (float4)(2) * i12 - i22;\n",
	"\n",
	"		Gy =   i00 - i20  + (float4)(2)*i01 - (float4)(2)*i21 + i02  -  i22;\n",
	"\n",
	"		Gx = native_divide(native_sqrt(Gx * Gx + Gy * Gy), (float4)(2));\n",
	"\n",
	"		write_imagef(outputImage, coord, convert_float4(Gx));\n",
	"	}\n",
	"}\n",
	"\n",
	"__kernel void copy(__read_only image2d_t srcImg,\n",
	"                              __write_only image2d_t dstImg,\n",
	"                              int width, int height)\n",
	"{\n",
	"\n",
	"    float kernelWeights[9] = { 1.0f, 1.0f, 1.0f,\n",
	"                               1.0f, 1.0f, 1.0f,\n",
	"                               1.0f, 1.0f, 1.0f};\n",
	"\n",
	"    int2 startImageCoord = (int2) (get_global_id(0) - 1, get_global_id(1) - 1);\n",
	"    int2 endImageCoord   = (int2) (get_global_id(0) + 1, get_global_id(1) + 1);\n",
	"    int2 outImageCoord = (int2) (get_global_id(0), get_global_id(1));\n",
	"\n",
	"    if (outImageCoord.x < width && outImageCoord.y < height)\n",
	"    {\n",
	"        int weight = 0;\n",
	"        float4 outColor = (float4)(0.0f, 0.0f, 0.0f, 0.0f);\n",
	"\n",
	"        const sampler_t sampler=CLK_NORMALIZED_COORDS_FALSE | CLK_ADDRESS_CLAMP | CLK_FILTER_NEAREST;\n",
	"        outColor = read_imagef(srcImg, sampler, outImageCoord);\n",
	"        write_imagef(dstImg, outImageCoord, outColor);\n",
	"    }\n",
	"}\n",
	"__kernel void hello_kernel(__global const float *a,\n",
	"                           __global const float *b,\n",
	"                           __global float *result)\n",
	"{\n",
	"    int gid = get_global_id(0);\n",
	"\n",
	"    result[gid] = a[gid] + b[gid];\n",
	"}\n",
	""};


static const size_t CL_TST_KERNELS_SIZE = sizeof(CL_TST_KERNELS) / sizeof(const char *);


static const char *CL_TRANSPOSE[] = { 
	"/*\n",
	" * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
	" *\n",
	" * Please refer to the NVIDIA end user license agreement (EULA) associated\n",
	" * with this source code for terms and conditions that govern your use of\n",
	" * this software. Any use, reproduction, disclosure, or distribution of\n",
	" * this software and related documentation outside the terms of the EULA\n",
	" * is strictly prohibited.\n",
	" *\n",
	" */\n",
	"\n",
	"/* Matrix transpose with OpenCL\n",
	"* Device code.\n",
	"*/\n",
	"\n",
	"#define BLOCK_DIM 16\n",
	"\n",
	"// This kernel is optimized to ensure all global reads and writes are coalesced,\n",
	"// and to avoid bank conflicts in shared memory.  This kernel is up to 11x faster\n",
	"// than the naive kernel below.  Note that the shared memory array is sized to \n",
	"// (BLOCK_DIM+1)*BLOCK_DIM.  This pads each row of the 2D block in shared memory \n",
	"// so that bank conflicts do not occur when threads address the array column-wise.\n",
	"__kernel void transpose(__global float *odata, __global float *idata, int offset, int width, int height, __local float* block)\n",
	"{\n",
	"	// read the matrix tile into shared memory\n",
	"	unsigned int xIndex = get_global_id(0);\n",
	"	unsigned int yIndex = get_global_id(1);\n",
	"\n",
	"	if((xIndex + offset < width) && (yIndex < height))\n",
	"	{\n",
	"		unsigned int index_in = yIndex * width + xIndex + offset;\n",
	"		block[get_local_id(1)*(BLOCK_DIM+1)+get_local_id(0)] = idata[index_in];\n",
	"	}\n",
	"\n",
	"	barrier(CLK_LOCAL_MEM_FENCE);\n",
	"\n",
	"	// write the transposed matrix tile to global memory\n",
	"	xIndex = get_group_id(1) * BLOCK_DIM + get_local_id(0);\n",
	"	yIndex = get_group_id(0) * BLOCK_DIM + get_local_id(1);\n",
	"	if((xIndex < height) && (yIndex + offset < width))\n",
	"    {\n",
	"		unsigned int index_out = yIndex * height + xIndex;\n",
	"		odata[index_out] = block[get_local_id(0)*(BLOCK_DIM+1)+get_local_id(1)];\n",
	"	}\n",
	"}\n",
	"\n",
	"\n",
	"\n",
	"// This naive transpose kernel suffers from completely non-coalesced writes.\n",
	"// It can be up to 10x slower than the kernel above for large matrices.\n",
	"__kernel void transpose_naive(__global float *odata, __global float* idata, int offset, int width, int height)\n",
	"{\n",
	"    unsigned int xIndex = get_global_id(0);\n",
	"    unsigned int yIndex = get_global_id(1);\n",
	"    \n",
	"    if (xIndex + offset < width && yIndex < height)\n",
	"    {\n",
	"        unsigned int index_in  = xIndex + offset + width * yIndex;\n",
	"        unsigned int index_out = yIndex + height * xIndex;\n",
	"        odata[index_out] = idata[index_in]; \n",
	"    }\n",
	"}\n",
	"\n",
	"\n",
	"__kernel void simple_copy(__global float *odata, __global float* idata, int offset, int width, int height)\n",
	"{\n",
	"    unsigned int xIndex = get_global_id(0);\n",
	"    unsigned int yIndex = get_global_id(1);\n",
	"    \n",
	"    if (xIndex + offset < width && yIndex < height)\n",
	"    {\n",
	"        unsigned int index_in  = xIndex + offset + width * yIndex;\n",
	"        odata[index_in] = idata[index_in]; \n",
	"    }\n",
	"}\n",
	"\n",
	"__kernel void shared_copy(__global float *odata, __global float *idata, int offset, int width, int height, __local float* block)\n",
	"{\n",
	"	// read the matrix tile into shared memory\n",
	"	unsigned int xIndex = get_global_id(0);\n",
	"	unsigned int yIndex = get_global_id(1);\n",
	"\n",
	"    unsigned int index_in = yIndex * width + xIndex + offset;\n",
	"	if((xIndex + offset< width) && (yIndex < height))\n",
	"	{\n",
	"		block[get_local_id(1)*(BLOCK_DIM+1)+get_local_id(0)] = idata[index_in];\n",
	"	}\n",
	"\n",
	"	barrier(CLK_LOCAL_MEM_FENCE);\n",
	"\n",
	"	if((xIndex < height) && (yIndex+ offset < width))\n",
	"    {\n",
	"		odata[index_in] = block[get_local_id(1)*(BLOCK_DIM+1)+get_local_id(0)];\n",
	"	}\n",
	"}\n",
	"\n",
	"\n",
	"__kernel void uncoalesced_copy(__global float *odata, __global float* idata, int offset, int width, int height)\n",
	"{\n",
	"    unsigned int xIndex = get_global_id(0);\n",
	"    unsigned int yIndex = get_global_id(1);\n",
	"    \n",
	"    if (xIndex + offset < width && yIndex < height)\n",
	"    {\n",
	"        unsigned int index_in  = yIndex + height * (xIndex+ offset);\n",
	"        odata[index_in] = idata[index_in]; \n",
	"    }\n",
	"}\n",
	""};


static const size_t CL_TRANSPOSE_SIZE = sizeof(CL_TRANSPOSE) / sizeof(const char *);


static const char *CL_MATRIXMUL[] = { 
	"/*\n",
	" * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
	" *\n",
	" * Please refer to the NVIDIA end user license agreement (EULA) associated\n",
	" * with this source code for terms and conditions that govern your use of\n",
	" * this software. Any use, reproduction, disclosure, or distribution of\n",
	" * this software and related documentation outside the terms of the EULA\n",
	" * is strictly prohibited.\n",
	" *\n",
	" */\n",
	"\n",
	"/* Matrix multiplication: C = A * B.\n",
	" * Device code.\n",
	" */\n",
	"\n",
	"#define AS(i, j) As[j + i * BLOCK_SIZE]\n",
	"#define BS(i, j) Bs[j + i * BLOCK_SIZE]\n",
	"\n",
	"///////////////////////////////////////////////////////////////////////////////\n",
	"//! Matrix multiplication on the device: C = A * B\n",
	"//! uiWA is A's width and uiWB is B's width\n",
	"////////////////////////////////////////////////////////////////////////////////\n",
	"__kernel void\n",
	"matrixMul( __global float* C, __global float* A, __global float* B, \n",
	"	   __local float* As, __local float* Bs, int uiWA, int uiWB, int trueLocalSize1)\n",
	"{\n",
	"    // Block index\n",
	"    int bx = get_group_id(0);\n",
	"    int by = get_group_id(1);\n",
	"\n",
	"    // Thread index\n",
	"    int tx = get_local_id(0);\n",
	"    int ty = get_local_id(1);\n",
	"\n",
	"    // Index of the first sub-matrix of A processed by the block\n",
	"    int aBegin = uiWA * BLOCK_SIZE * by;\n",
	"\n",
	"    // Index of the last sub-matrix of A processed by the block\n",
	"    int aEnd   = aBegin + uiWA - 1;\n",
	"\n",
	"    // Step size used to iterate through the sub-matrices of A\n",
	"    int aStep  = BLOCK_SIZE;\n",
	"\n",
	"    // Index of the first sub-matrix of B processed by the block\n",
	"    int bBegin = BLOCK_SIZE * bx;\n",
	"\n",
	"    // Step size used to iterate through the sub-matrices of B\n",
	"    int bStep  = BLOCK_SIZE * uiWB;\n",
	"\n",
	"    // Csub is used to store the element of the block sub-matrix\n",
	"    // that is computed by the thread\n",
	"    float Csub = 0.0f;\n",
	"\n",
	"    // Loop over all the sub-matrices of A and B\n",
	"    // required to compute the block sub-matrix\n",
	"    for (int a = aBegin, b = bBegin;\n",
	"             a <= aEnd;\n",
	"             a += aStep, b += bStep) {\n",
	"\n",
	"        // Load the matrices from device memory\n",
	"        // to shared memory; each thread loads\n",
	"        // one element of each matrix\n",
	"        AS(ty, tx) = A[a + uiWA * ty + tx];\n",
	"        BS(ty, tx) = B[b + uiWB * ty + tx];\n",
	"	\n",
	"        // Synchronize to make sure the matrices are loaded\n",
	"        barrier(CLK_LOCAL_MEM_FENCE);\n",
	"\n",
	"        // Multiply the two matrices together;\n",
	"        // each thread computes one element\n",
	"        // of the block sub-matrix        \n",
	"        #pragma unroll\n",
	"        for (int k = 0; k < BLOCK_SIZE; ++k)\n",
	"            Csub += AS(ty, k) * BS(k, tx);\n",
	"\n",
	"        // Synchronize to make sure that the preceding\n",
	"        // computation is done before loading two new\n",
	"        // sub-matrices of A and B in the next iteration\n",
	"        barrier(CLK_LOCAL_MEM_FENCE);\n",
	"    }\n",
	"\n",
	"    if (get_global_id(1) < trueLocalSize1)\n",
	"    // Write the block sub-matrix to device memory;\n",
	"    // each thread writes one element\n",
	"    C[get_global_id(1) * get_global_size(0) + get_global_id(0)] = Csub;\n",
	"\n",
	"}\n",
	"\n",
	""};


static const size_t CL_MATRIXMUL_SIZE = sizeof(CL_MATRIXMUL) / sizeof(const char *);


#endif

/* ###### End AutoGenerated File. ###### */
