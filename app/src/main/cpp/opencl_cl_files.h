/* ###### AutoGenerated File. Generated Data:Mon May 04 21:35:29 EEST 2020 ###### */

#ifndef __OPENCL_CL_FILES_H__
#define __OPENCL_CL_FILES_H__

#include <stddef.h>

static const char *CL_OCLMATVECMUL[] = { 
	"/*\n",
	" * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
	" *\n",
	" * Please refer to the NVIDIA end user license agreement (EULA) associated\n",
	" * with this source code for terms and conditions that govern your use of\n",
	" * this software. Any use, reproduction, disclosure, or distribution of\n",
	" * this software and related documentation outside the terms of the EULA\n",
	" * is strictly prohibited.\n",
	" *\n",
	" */\n",
	" \n",
	"/* Matrix-vector multiplication: W = M * V.\n",
	" * Device code.\n",
	" *\n",
	" * This sample implements matrix-vector multiplication.\n",
	" * It has been written for clarity of exposition to illustrate various OpenCL\n",
	" * programming principles and optimizatoins, not with the goal of providing\n",
	" * the most performant generic kernel for matrix-vector multiplication.\n",
	" *\n",
	" * CUBLAS provides high-performance matrix-vector multiplication on GPU.\n",
	" */\n",
	" \n",
	"// Matrix multiplication kernel called by MatrixMul()\n",
	"__kernel void MatVecMulUncoalesced0(const __global float* M,\n",
	"                                    const __global float* V,\n",
	"                                    uint width, uint height,\n",
	"                                    __global float* W)\n",
	"{\n",
	"    // Row index\n",
	"    uint y = get_global_id(0);\n",
	"    if (y < height) {\n",
	"    \n",
	"        // Row pointer\n",
	"        const __global float* row = M + y * width;\n",
	"\n",
	"        // Compute dot product  \n",
	"        float dotProduct = 0;\n",
	"        for (int x = 0; x < width; ++x)\n",
	"            dotProduct += row[x] * V[x];\n",
	"\n",
	"        // Write result to global memory\n",
	"        W[y] = dotProduct;\n",
	"    }\n",
	"}\n",
	"\n",
	"// Matrix multiplication kernel called by MatrixMul()\n",
	"__kernel void MatVecMulUncoalesced1(const __global float* M,\n",
	"                                    const __global float* V,\n",
	"                                    uint width, uint height,\n",
	"                                    __global float* W)\n",
	"{        \n",
	"    // Each work-item handles as many matrix rows as necessary\n",
	"    for (uint y = get_global_id(0);\n",
	"         y < height;\n",
	"         y += get_global_size(0))\n",
	"    {\n",
	"\n",
	"        // Row pointer\n",
	"        const __global float* row = M + y * width;\n",
	"\n",
	"        // Compute dot product  \n",
	"        float dotProduct = 0;\n",
	"        for (uint x = 0; x < width; ++x)\n",
	"            dotProduct += row[x] * V[x];\n",
	"\n",
	"        // Write result to global memory\n",
	"        W[y] = dotProduct;\n",
	"    }\n",
	"}\n",
	"\n",
	"// Matrix multiplication kernel called by MatrixMul()\n",
	"__kernel void MatVecMulCoalesced0(const __global float* M,\n",
	"                                  const __global float* V,\n",
	"                                  uint width, uint height,\n",
	"                                  __global float* W,\n",
	"                                  __local float* partialDotProduct)\n",
	"{    \n",
	"    // Each work-group handles as many matrix rows as necessary\n",
	"    for (uint y = get_group_id(0); y < height; y += get_num_groups(0)) {\n",
	"\n",
	"        // Row pointer\n",
	"        const __global float* row = M + y * width;\n",
	"        \n",
	"        // Each work-item accumulates as many products as necessary\n",
	"        // into local variable \"sum\"\n",
	"        float sum = 0;\n",
	"        for (uint x = get_local_id(0); x < width; x += get_local_size(0))\n",
	"            sum += row[x] * V[x];\n",
	"\n",
	"        // Each partial dot product is stored in shared memory\n",
	"        partialDotProduct[get_local_id(0)] = sum;\n",
	"\n",
	"        // Synchronize to make sure each work-item is done updating\n",
	"        // shared memory; this is necessary because in the next step,\n",
	"        // the first work-item needs to read from shared memory\n",
	"        // the partial dot products written by the other work-items\n",
	"        barrier(CLK_LOCAL_MEM_FENCE);\n",
	"\n",
	"        // The first work-item in the work-group adds all partial\n",
	"        // dot products together and writes the result to global memory\n",
	"        if (get_local_id(0) == 0) {\n",
	"            float dotProduct = 0;\n",
	"            for (uint t = 0; t < get_local_size(0); ++t)\n",
	"                dotProduct += partialDotProduct[t];\n",
	"            W[y] = dotProduct;\n",
	"	    }\n",
	"\n",
	"        // Synchronize to make sure the first work-item is done with\n",
	"        // reading partialDotProduct\n",
	"        barrier(CLK_LOCAL_MEM_FENCE);\n",
	"	}\n",
	"}\n",
	"\n",
	"// Matrix multiplication kernel called by MatrixMul()\n",
	"__kernel void MatVecMulCoalesced1(const __global float* M,\n",
	"                                  const __global float* V,\n",
	"                                  uint width, uint height,\n",
	"                                  __global float* W,\n",
	"                                  __local float* partialDotProduct)\n",
	"{    \n",
	"    // Each work-group handles as many matrix rows as necessary\n",
	"    for (uint y = get_group_id(0); y < height; y += get_num_groups(0)) {\n",
	"\n",
	"        // Row pointer\n",
	"        const __global float* row = M + y * width;\n",
	"        \n",
	"        // Each work-item accumulates as many products as necessary\n",
	"        // into local variable \"sum\"\n",
	"        float sum = 0;\n",
	"        for (uint x = get_local_id(0); x < width; x += get_local_size(0))\n",
	"            sum += row[x] * V[x];\n",
	"\n",
	"        // Each partial dot product is stored in shared memory\n",
	"        partialDotProduct[get_local_id(0)] = sum;\n",
	"        \n",
	"        // Perform parallel reduction to add each work-item's\n",
	"        // partial dot product together\n",
	"        for (uint stride = 1; stride < get_local_size(0); stride *= 2) {\n",
	"\n",
	"            // Synchronize to make sure each work-item is done updating\n",
	"            // shared memory; this is necessary because work-items read\n",
	"            // results that have been written by other work-items\n",
	"            barrier(CLK_LOCAL_MEM_FENCE);\n",
	"            \n",
	"            // Index into the \"partialDotProduct\" array where\n",
	"            // the work-item will write during this step\n",
	"            uint index = 2 * stride * get_local_id(0);\n",
	"            \n",
	"            // Check for valid indices\n",
	"            if (index < get_local_size(0)) {\n",
	"            \n",
	"                // Add two elements from the \"partialDotProduct\" array\n",
	"                // and store the result in partialDotProduct[index]\n",
	"                partialDotProduct[index] += partialDotProduct[index + stride];\n",
	"            }\n",
	"        }\n",
	"\n",
	"        // Write the result of the reduction to global memory\n",
	"        if (get_local_id(0) == 0)\n",
	"            W[y] = partialDotProduct[0];\n",
	"\n",
	"        // Synchronize to make sure the first work-item is done with\n",
	"        // reading partialDotProduct\n",
	"        barrier(CLK_LOCAL_MEM_FENCE);\n",
	"    }\n",
	"}\n",
	"\n",
	"// Matrix multiplication kernel called by MatrixMul()\n",
	"__kernel void MatVecMulCoalesced2(const __global float* M,\n",
	"                                  const __global float* V,\n",
	"                                  uint width, uint height,\n",
	"                                  __global float* W,\n",
	"                                  __local float* partialDotProduct)\n",
	"{    \n",
	"    // Each work-group handles as many matrix rows as necessary\n",
	"    for (uint y = get_group_id(0); y < height; y += get_num_groups(0)) {\n",
	"\n",
	"        // Row pointer\n",
	"        const __global float* row = M + y * width;\n",
	"        \n",
	"        // Each work-item accumulates as many products as necessary\n",
	"        // into local variable \"sum\"\n",
	"        float sum = 0;\n",
	"        for (uint x = get_local_id(0); x < width; x += get_local_size(0))\n",
	"            sum += row[x] * V[x];\n",
	"\n",
	"        // Each partial dot product is stored in shared memory\n",
	"        partialDotProduct[get_local_id(0)] = sum;\n",
	"        \n",
	"        // Perform parallel reduction to add each work-item's\n",
	"        // partial dot product together\n",
	"        for (uint stride = get_local_size(0) / 2; stride > 0; stride /= 2) {\n",
	"\n",
	"            // Synchronize to make sure each work-item is done updating\n",
	"            // shared memory; this is necessary because work-items read\n",
	"            // results that have been written by other work-items\n",
	"            barrier(CLK_LOCAL_MEM_FENCE);\n",
	"            \n",
	"            // Only the first work-items in the work-group add elements together\n",
	"            if (get_local_id(0) < stride) {\n",
	"            \n",
	"                // Add two elements from the \"partialDotProduct\" array\n",
	"                // and store the result in partialDotProduct[index]\n",
	"                partialDotProduct[get_local_id(0)] += partialDotProduct[get_local_id(0) + stride];\n",
	"            }\n",
	"        }\n",
	"\n",
	"        // Write the result of the reduction to global memory\n",
	"        if (get_local_id(0) == 0)\n",
	"            W[y] = partialDotProduct[0];\n",
	"\n",
	"        // Synchronize to make sure the first work-item is done with\n",
	"        // reading partialDotProduct\n",
	"        barrier(CLK_LOCAL_MEM_FENCE);\n",
	"    }\n",
	"}\n",
	"\n",
	"#define WARP_SIZE 32\n",
	"__kernel void MatVecMulCoalesced3(const __global float* M,\n",
	"                                  const __global float* V,\n",
	"                                  uint width, uint height,\n",
	"                                  __global float* W,\n",
	"                                  __local float* partialDotProduct)\n",
	"{\n",
	"   // Each work-group computes multiple elements of W\n",
	"   for (uint y = get_group_id(0); y < height; y += get_num_groups(0)) {\n",
	"      const __global float* row = M + y * width;\n",
	"\n",
	"      // Each work-item accumulates as many products as necessary\n",
	"      // into local variable \"sum\"\n",
	"      float sum = 0;\n",
	"      for (uint x = get_local_id(0); x < width; x += get_local_size(0))\n",
	"         sum += row[x] * V[x];\n",
	"\n",
	"      // Each partial dot product is stored in shared memory\n",
	"      partialDotProduct[get_local_id(0)] = sum;\n",
	"\n",
	"      // Perform parallel reduction to add each work-item's\n",
	"      // partial dot product together\n",
	"\n",
	"      // Synchronize to make sure each work-item is done writing to\n",
	"      // partialDotProduct\n",
	"      barrier(CLK_LOCAL_MEM_FENCE);\n",
	"\n",
	"      // Thread local ID within a warp\n",
	"      uint id = get_local_id(0) & (WARP_SIZE - 1); \n",
	"\n",
	"      // Each warp reduces 64 consecutive elements\n",
	"      float warpResult = 0.0f;\n",
	"      if (get_local_id(0) < get_local_size(0)/2 )\n",
	"      {\n",
	"          volatile __local float* p = partialDotProduct + 2 * get_local_id(0) - id;\n",
	"          p[0] += p[32];\n",
	"          p[0] += p[16];\n",
	"          p[0] += p[8];\n",
	"          p[0] += p[4];\n",
	"          p[0] += p[2];\n",
	"          p[0] += p[1];\n",
	"          warpResult = p[0];\n",
	"      }\n",
	"\n",
	"      // Synchronize to make sure each warp is done reading\n",
	"      // partialDotProduct before it is overwritten in the next step\n",
	"      barrier(CLK_LOCAL_MEM_FENCE);\n",
	"\n",
	"      // The first thread of each warp stores the result of the reduction\n",
	"      // at the beginning of partialDotProduct\n",
	"      if (id == 0)\n",
	"         partialDotProduct[get_local_id(0) / WARP_SIZE] = warpResult;\n",
	"\n",
	"      // Synchronize to make sure each warp is done writing to\n",
	"      // partialDotProduct before it is read in the next step\n",
	"      barrier(CLK_LOCAL_MEM_FENCE);\n",
	"\n",
	"      // Number of remaining elements after the first reduction\n",
	"      uint size = get_local_size(0) / (2 * WARP_SIZE);\n",
	"\n",
	"      // get_local_size(0) is less or equal to 512 on NVIDIA GPUs, so\n",
	"      // only a single warp is needed for the following last reduction\n",
	"      // step\n",
	"      if (get_local_id(0) < size / 2) {\n",
	"         volatile __local float* p = partialDotProduct + get_local_id(0);\n",
	"         if (size >= 8)\n",
	"            p[0] += p[4];\n",
	"         if (size >= 4)\n",
	"            p[0] += p[2];\n",
	"         if (size >= 2)\n",
	"            p[0] += p[1];\n",
	"      }\n",
	"\n",
	"      // Write the result of the reduction to global memory\n",
	"      if (get_local_id(0) == 0)\n",
	"         W[y] = partialDotProduct[0];\n",
	"\n",
	"      // Synchronize to make sure the first work-item is done with\n",
	"      // reading partialDotProduct\n",
	"      barrier(CLK_LOCAL_MEM_FENCE);\n",
	"   }\n",
	"}\n",
	""};


static const size_t CL_OCLMATVECMUL_SIZE = sizeof(CL_OCLMATVECMUL) / sizeof(const char *);


static const char *CL_TRANSPOSE[] = { 
	"/*\n",
	" * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
	" *\n",
	" * Please refer to the NVIDIA end user license agreement (EULA) associated\n",
	" * with this source code for terms and conditions that govern your use of\n",
	" * this software. Any use, reproduction, disclosure, or distribution of\n",
	" * this software and related documentation outside the terms of the EULA\n",
	" * is strictly prohibited.\n",
	" *\n",
	" */\n",
	"\n",
	"/* Matrix transpose with OpenCL\n",
	"* Device code.\n",
	"*/\n",
	"\n",
	"#define BLOCK_DIM 16\n",
	"\n",
	"// This kernel is optimized to ensure all global reads and writes are coalesced,\n",
	"// and to avoid bank conflicts in shared memory.  This kernel is up to 11x faster\n",
	"// than the naive kernel below.  Note that the shared memory array is sized to \n",
	"// (BLOCK_DIM+1)*BLOCK_DIM.  This pads each row of the 2D block in shared memory \n",
	"// so that bank conflicts do not occur when threads address the array column-wise.\n",
	"__kernel void transpose(__global float *odata, __global float *idata, int offset, int width, int height, __local float* block)\n",
	"{\n",
	"	// read the matrix tile into shared memory\n",
	"	unsigned int xIndex = get_global_id(0);\n",
	"	unsigned int yIndex = get_global_id(1);\n",
	"\n",
	"	if((xIndex + offset < width) && (yIndex < height))\n",
	"	{\n",
	"		unsigned int index_in = yIndex * width + xIndex + offset;\n",
	"		block[get_local_id(1)*(BLOCK_DIM+1)+get_local_id(0)] = idata[index_in];\n",
	"	}\n",
	"\n",
	"	barrier(CLK_LOCAL_MEM_FENCE);\n",
	"\n",
	"	// write the transposed matrix tile to global memory\n",
	"	xIndex = get_group_id(1) * BLOCK_DIM + get_local_id(0);\n",
	"	yIndex = get_group_id(0) * BLOCK_DIM + get_local_id(1);\n",
	"	if((xIndex < height) && (yIndex + offset < width))\n",
	"    {\n",
	"		unsigned int index_out = yIndex * height + xIndex;\n",
	"		odata[index_out] = block[get_local_id(0)*(BLOCK_DIM+1)+get_local_id(1)];\n",
	"	}\n",
	"}\n",
	"\n",
	"\n",
	"\n",
	"// This naive transpose kernel suffers from completely non-coalesced writes.\n",
	"// It can be up to 10x slower than the kernel above for large matrices.\n",
	"__kernel void transpose_naive(__global float *odata, __global float* idata, int offset, int width, int height)\n",
	"{\n",
	"    unsigned int xIndex = get_global_id(0);\n",
	"    unsigned int yIndex = get_global_id(1);\n",
	"    \n",
	"    if (xIndex + offset < width && yIndex < height)\n",
	"    {\n",
	"        unsigned int index_in  = xIndex + offset + width * yIndex;\n",
	"        unsigned int index_out = yIndex + height * xIndex;\n",
	"        odata[index_out] = idata[index_in]; \n",
	"    }\n",
	"}\n",
	"\n",
	"\n",
	"__kernel void simple_copy(__global float *odata, __global float* idata, int offset, int width, int height)\n",
	"{\n",
	"    unsigned int xIndex = get_global_id(0);\n",
	"    unsigned int yIndex = get_global_id(1);\n",
	"    \n",
	"    if (xIndex + offset < width && yIndex < height)\n",
	"    {\n",
	"        unsigned int index_in  = xIndex + offset + width * yIndex;\n",
	"        odata[index_in] = idata[index_in]; \n",
	"    }\n",
	"}\n",
	"\n",
	"__kernel void shared_copy(__global float *odata, __global float *idata, int offset, int width, int height, __local float* block)\n",
	"{\n",
	"	// read the matrix tile into shared memory\n",
	"	unsigned int xIndex = get_global_id(0);\n",
	"	unsigned int yIndex = get_global_id(1);\n",
	"\n",
	"    unsigned int index_in = yIndex * width + xIndex + offset;\n",
	"	if((xIndex + offset< width) && (yIndex < height))\n",
	"	{\n",
	"		block[get_local_id(1)*(BLOCK_DIM+1)+get_local_id(0)] = idata[index_in];\n",
	"	}\n",
	"\n",
	"	barrier(CLK_LOCAL_MEM_FENCE);\n",
	"\n",
	"	if((xIndex < height) && (yIndex+ offset < width))\n",
	"    {\n",
	"		odata[index_in] = block[get_local_id(1)*(BLOCK_DIM+1)+get_local_id(0)];\n",
	"	}\n",
	"}\n",
	"\n",
	"\n",
	"__kernel void uncoalesced_copy(__global float *odata, __global float* idata, int offset, int width, int height)\n",
	"{\n",
	"    unsigned int xIndex = get_global_id(0);\n",
	"    unsigned int yIndex = get_global_id(1);\n",
	"    \n",
	"    if (xIndex + offset < width && yIndex < height)\n",
	"    {\n",
	"        unsigned int index_in  = yIndex + height * (xIndex+ offset);\n",
	"        odata[index_in] = idata[index_in]; \n",
	"    }\n",
	"}\n",
	""};


static const size_t CL_TRANSPOSE_SIZE = sizeof(CL_TRANSPOSE) / sizeof(const char *);


static const char *CL_EXINOS[] = { 
	"    #pragma OPENCL EXTENSION cl_khr_fp16 : enable\n",
	"    __constant sampler_t sampler =	CLK_NORMALIZED_COORDS_FALSE|CLK_ADDRESS_CLAMP|CLK_FILTER_NEAREST;\n",
	"    __kernel void compute_cell_features(__global const float*     mag,\n",
	"           __global const float*      angle,\n",
	"           __constant const short*   shape __attribute__((max_constant_size(452))),\n",
	"           __constant const char*    lut1 __attribute__((max_constant_size(288))),\n",
	"           __constant const float*    lut2 __attribute__((max_constant_size(1152))),\n",
	"           __global float*            _allBlockVecs,\n",
	"           float                      bin_interval,\n",
	"           int                       block_vec_length,\n",
	"           int                       src_width,\n",
	"           int                       src_height)\n",
	"    {\n",
	"        const int wid_z = get_global_id(0);\n",
	"        const int wid_x = get_global_id(1);\n",
	"        const int wid_y = get_global_id(2);\n",
	"        const int CELL_SIZE = 12;\n",
	"        const int NUM_OF_ORIENTATION_BINS = 8;\n",
	"        float magnitude, pixel, fraction, mw1, mw2;\n",
	"        char2 xyMinus;\n",
	"        float4 wxwy;\n",
	"        int bin1, bin2, binx, biny, whole;\n",
	"        int row = wid_y/CELL_SIZE;\n",
	"        int col = wid_x/CELL_SIZE;\n",
	"        int x = (int) shape[wid_z];\n",
	"        int y = (int) shape[wid_z + 113];\n",
	"        int offsetRow = y - CELL_SIZE + wid_y;\n",
	"        int offsetCol = x - CELL_SIZE + wid_x;\n",
	"        int stride = wid_z * block_vec_length;\n",
	"//            int dif = - offsetCol - offsetRow*CELL_SIZE;\n",
	"        int idxLUT = (wid_x - col*CELL_SIZE) + (wid_y - row*CELL_SIZE)*CELL_SIZE;\n",
	"        idxLUT = idxLUT<<1;\n",
	"        int idxLUT2 = idxLUT<<1;\n",
	"        int idxSRC = offsetRow*src_width + offsetCol;\n",
	"        int cellIndex;\n",
	"                magnitude = mag[idxSRC];\n",
	"                pixel = angle[idxSRC];\n",
	"                bin1 = 0;\n",
	"                bin2 = 0;\n",
	"                if (pixel <= 0) {\n",
	"                    pixel +=180;\n",
	"                    bin1 += NUM_OF_ORIENTATION_BINS;\n",
	"                    bin2 += NUM_OF_ORIENTATION_BINS;\n",
	"                }\n",
	"                pixel /= bin_interval;\n",
	"                whole = pixel;\n",
	"                fraction = pixel - whole;\n",
	"                if (whole != NUM_OF_ORIENTATION_BINS - 1) bin1 += whole + 1;\n",
	"                bin2 += whole;\n",
	"                xyMinus = vload2(0, lut1 + idxLUT);\n",
	"                wxwy = vload4(0, lut2 + idxLUT2);\n",
	"                binx = xyMinus.s0 + col;\n",
	"                biny = xyMinus.s1 + row;\n",
	"                mw1 = magnitude * fraction;\n",
	"                mw2 = magnitude - mw1;\n",
	"                int startBin1 = bin1 * 4 + stride;\n",
	"                int startBin2 = bin2 * 4 + stride;\n",
	"                if(binx >= 0 && biny >= 0){\n",
	"                    cellIndex = biny * 2 + binx;\n",
	"                    _allBlockVecs[startBin1 + cellIndex] += mw1 * wxwy.s0;\n",
	"                    _allBlockVecs[startBin2 + cellIndex] += mw2 * wxwy.s0;\n",
	"                }\n",
	"                if(binx < 1 && biny >= 0){\n",
	"                    cellIndex = (biny * 2 + (binx + 1));\n",
	"                    _allBlockVecs[startBin1 + cellIndex] += mw1 * wxwy.s1;\n",
	"                    _allBlockVecs[startBin2 + cellIndex] += mw2 * wxwy.s1;\n",
	"                }\n",
	"                if(binx < 1 && biny < 1){\n",
	"                    cellIndex = ((biny + 1) * 2 + (binx + 1));\n",
	"                    _allBlockVecs[startBin1 + cellIndex] += mw1 * wxwy.s2;\n",
	"                    _allBlockVecs[startBin2 + cellIndex] += mw2 * wxwy.s2;\n",
	"                }\n",
	"                if(binx >= 0 && biny < 1){\n",
	"                    cellIndex = ((biny + 1) * 2 + binx);\n",
	"                    _allBlockVecs[startBin1 + cellIndex] += mw1 * wxwy.s3;\n",
	"                    _allBlockVecs[startBin2 + cellIndex] += mw2 * wxwy.s3;\n",
	"                }\n",
	"    }\n",
	"    __kernel void normalize_vec(__global float*     _allBlockVecs)\n",
	"    {\n",
	"        const int wid_z = get_global_id(0);\n",
	"        float16 sum;\n",
	"    int start = wid_z * 100;\n",
	"    int stride = 32;\n",
	"    int start2 = start + stride;\n",
	"    int start3 = start2 + stride;\n",
	"    int start4 = start3 + stride;\n",
	"    float16 h1, h2, h3, h4, h11, h21, h31, h41, hc1, hc2;\n",
	"    h1 = vload16(0, _allBlockVecs + start);\n",
	"    h2 = vload16(0, _allBlockVecs + start + 16);\n",
	"    h3 = vload16(0, _allBlockVecs + start + 32);\n",
	"    h4 = vload16(0, _allBlockVecs + start + 48);\n",
	"    h11 = fabs(h1);\n",
	"    h21 = fabs(h2);\n",
	"    h31 = fabs(h3);\n",
	"    h41 = fabs(h4);\n",
	"    sum = (fmax(h11, h31) + fmax(h21, h41))*0.960433870103f + (fmin(h11, h31) + fmin(h21, h41))*0.397824734759f;\n",
	"    float factor = 1.0 / (sum.s0 + sum.s1 + sum.s2 + sum.s3 + sum.s4 + sum.s5 + sum.s6 + sum.s7 + sum.s8 + sum.s9 + sum.sA + sum.sB + sum.sC + sum.sD + sum.sE + sum.sF + 1e-9);\n",
	"//        float text[4] = {0.0, 0.0, 0.0, 0.0};\n",
	"    float4 text1;\n",
	"    h1 *= factor;\n",
	"    h2 *= factor;\n",
	"    h3 *= factor;\n",
	"    h4 *= factor;\n",
	"    hc1 = h1 + h3;\n",
	"    hc2 = h2 + h4;\n",
	"    text1.s0 = hc1.s0 + hc1.s4 + hc1.s8 + hc1.sC + hc2.s0 + hc2.s4 + hc2.s8 + hc2.sC;\n",
	"    text1.s1 = hc1.s1 + hc1.s5 + hc1.s9 + hc1.sD + hc2.s1 + hc2.s5 + hc2.s9 + hc2.sD;\n",
	"    text1.s2 = hc1.s2 + hc1.s6 + hc1.sA + hc1.sE + hc2.s2 + hc2.s6 + hc2.sA + hc2.sE;\n",
	"    text1.s3 = hc1.s3 + hc1.s7 + hc1.sB + hc1.sF + hc2.s3 + hc2.s7 + hc2.sB + hc2.sF;\n",
	"    text1 *= (float) 0.2357;\n",
	"    vstore16(h1, 0, _allBlockVecs + start);\n",
	"    vstore16(h2, 0, _allBlockVecs + start + 16);\n",
	"    vstore16(h3, 0, _allBlockVecs + start + 32);\n",
	"    vstore16(h4, 0, _allBlockVecs + start + 48);\n",
	"    vstore16(hc1, 0, _allBlockVecs + start + 64);\n",
	"    vstore16(hc2, 0, _allBlockVecs + start + 80);\n",
	"    vstore4(text1, 0, _allBlockVecs + start + 96);\n",
	"    }\n",
	"    \n",
	"    __kernel void normalize_vec2(__global float*     _allBlockVecs)\n",
	"    {\n",
	"        const int wid_z = get_global_id(0);\n",
	"        int sum = 0;\n",
	"    int start = wid_z * 100;\n",
	"    int stride = 32;\n",
	"    int start2 = start + stride;\n",
	"    int start3 = start2 + stride;\n",
	"    int start4 = start3 + stride;\n",
	"    for(int i = start, i2 = start2;i < start + stride;i++, i2++)\n",
	"    {\n",
	"        float h1 = fabs(_allBlockVecs[i]);\n",
	"        float h2 = fabs(_allBlockVecs[i2]);\n",
	"        float h = fmax(h1, h2)*0.960433870103f + fmin(h1, h2)*0.397824734759f;\n",
	"        sum += h;\n",
	"    }\n",
	"    float factor = 1.0 / (sum + 1e-9);\n",
	"    float text[4] = {0.0, 0.0, 0.0, 0.0};\n",
	"    for(int i = start, i2 = start2, i3 = start3; i < start + stride; ++i, ++i2, ++i3){\n",
	"        float ha = _allBlockVecs[i];\n",
	"        float hb = _allBlockVecs[i2];\n",
	"        ha *= factor;\n",
	"        hb *= factor;\n",
	"        float hc = ha + hb;\n",
	"        text[i % 4] += hc;\n",
	"        _allBlockVecs[i]  = ha;\n",
	"        _allBlockVecs[i2] = hb;\n",
	"        _allBlockVecs[i3] = hc;\n",
	"    }\n",
	"    for(int i = 0; i < 4; i++){\n",
	"        _allBlockVecs[start4 + i] = 0.2357 * text[i];\n",
	"    }\n",
	"    }\n",
	"    \n",
	"    __kernel void pyr_down_opt2(__global const uchar*  restrict   src_img,\n",
	"                           __global uchar*     restrict      result_img,\n",
	"                           __constant const uchar*    pyr_mat __attribute__((max_constant_size(25))),\n",
	"                                   int                       src_width,\n",
	"                                   int                       src_size,\n",
	"                                   int                       result_width)\n",
	"    {\n",
	"        const int result_x = get_global_id(0)<<1;\n",
	"        const int result_y = get_global_id(1)<<1;\n",
	"        const int wid_x = result_x<<1;\n",
	"        const int wid_y = result_y<<1;\n",
	"        int idx = 0;\n",
	"        int idx1 = (wid_y - 2)*src_width + wid_x - 2;\n",
	"        int idx2 = idx1;\n",
	"        int idx3 = result_y * result_width + result_x;\n",
	"        uchar8 data[7];\n",
	"        uchar2 result[2];\n",
	"    #pragma unroll \n",
	"        for (int i = 0; i < 7; ++i)\n",
	"        {\n",
	"           data[i] = vload8(0, src_img + idx2);\n",
	"           idx2+=src_width;\n",
	"        }\n",
	"        int result_1 = data[0].s0 * pyr_mat[0] + data[0].s1 * pyr_mat[1] + data[0].s2 * pyr_mat[2] + data[0].s3 * pyr_mat[3] + data[0].s4 * pyr_mat[4] +\n",
	"                       data[1].s0 * pyr_mat[5] + data[1].s1 * pyr_mat[6] + data[1].s2 * pyr_mat[7] + data[1].s3 * pyr_mat[8] + data[1].s4 * pyr_mat[9] +\n",
	"                       data[2].s0 * pyr_mat[10] + data[2].s1 * pyr_mat[11] + data[2].s2 * pyr_mat[12] + data[2].s3 * pyr_mat[13] + data[2].s4 * pyr_mat[14] +\n",
	"                       data[3].s0 * pyr_mat[15] + data[3].s1 * pyr_mat[16] + data[3].s2 * pyr_mat[17] + data[3].s3 * pyr_mat[18] + data[3].s4 * pyr_mat[19] +\n",
	"                       data[4].s0 * pyr_mat[20] + data[4].s1 * pyr_mat[21] + data[4].s2 * pyr_mat[22] + data[4].s3 * pyr_mat[23] + data[4].s4 * pyr_mat[24];\n",
	"        int result_2 = data[0].s2 * pyr_mat[0] + data[0].s3 * pyr_mat[1] + data[0].s4 * pyr_mat[2] + data[0].s5 * pyr_mat[3] + data[0].s6 * pyr_mat[4] +\n",
	"                       data[1].s2 * pyr_mat[5] + data[1].s3 * pyr_mat[6] + data[1].s4 * pyr_mat[7] + data[1].s5 * pyr_mat[8] + data[1].s6 * pyr_mat[9] +\n",
	"                       data[2].s2 * pyr_mat[10] + data[2].s3 * pyr_mat[11] + data[2].s4 * pyr_mat[12] + data[2].s5 * pyr_mat[13] + data[2].s6 * pyr_mat[14] +\n",
	"                       data[3].s2 * pyr_mat[15] + data[3].s3 * pyr_mat[16] + data[3].s4 * pyr_mat[17] + data[3].s5 * pyr_mat[18] + data[3].s6 * pyr_mat[19] +\n",
	"                       data[4].s2 * pyr_mat[20] + data[4].s3 * pyr_mat[21] + data[4].s4 * pyr_mat[22] + data[4].s5 * pyr_mat[23] + data[4].s6 * pyr_mat[24];\n",
	"\n",
	"        int result_3 = data[2].s0 * pyr_mat[0] + data[2].s1 * pyr_mat[1] + data[2].s2 * pyr_mat[2] + data[2].s3 * pyr_mat[3] + data[2].s4 * pyr_mat[4] +\n",
	"                       data[3].s0 * pyr_mat[5] + data[3].s1 * pyr_mat[6] + data[3].s2 * pyr_mat[7] + data[3].s3 * pyr_mat[8] + data[3].s4 * pyr_mat[9] +\n",
	"                       data[4].s0 * pyr_mat[10] + data[4].s1 * pyr_mat[11] + data[4].s2 * pyr_mat[12] + data[4].s3 * pyr_mat[13] + data[4].s4 * pyr_mat[14] +\n",
	"                       data[5].s0 * pyr_mat[15] + data[5].s1 * pyr_mat[16] + data[5].s2 * pyr_mat[17] + data[5].s3 * pyr_mat[18] + data[5].s4 * pyr_mat[19] +\n",
	"                       data[6].s0 * pyr_mat[20] + data[6].s1 * pyr_mat[21] + data[6].s2 * pyr_mat[22] + data[6].s3 * pyr_mat[23] + data[6].s4 * pyr_mat[24];\n",
	"        int result_4 = data[2].s2 * pyr_mat[0] + data[2].s3 * pyr_mat[1] + data[2].s4 * pyr_mat[2] + data[2].s5 * pyr_mat[3] + data[2].s6 * pyr_mat[4] +\n",
	"                       data[3].s2 * pyr_mat[5] + data[3].s3 * pyr_mat[6] + data[3].s4 * pyr_mat[7] + data[3].s5 * pyr_mat[8] + data[3].s6 * pyr_mat[9] +\n",
	"                       data[4].s2 * pyr_mat[10] + data[4].s3 * pyr_mat[11] + data[4].s4 * pyr_mat[12] + data[4].s5 * pyr_mat[13] + data[4].s6 * pyr_mat[14] +\n",
	"                       data[5].s2 * pyr_mat[15] + data[5].s3 * pyr_mat[16] + data[5].s4 * pyr_mat[17] + data[5].s5 * pyr_mat[18] + data[5].s6 * pyr_mat[19] +\n",
	"                       data[6].s2 * pyr_mat[20] + data[6].s3 * pyr_mat[21] + data[6].s4 * pyr_mat[22] + data[6].s5 * pyr_mat[23] + data[6].s6 * pyr_mat[24];\n",
	"            result[0].s0 = result_1>>8;\n",
	"            result[0].s1 = result_2>>8;\n",
	"            result[1].s0 = result_3>>8;\n",
	"            result[1].s1 = result_4>>8;\n",
	"            vstore2(result[0], 0, result_img + idx3);\n",
	"            vstore2(result[1], 0, result_img + idx3 + result_width);\n",
	"    }\n",
	"    \n",
	" __kernel void pyr_down(__global const uchar*  restrict   src_img,\n",
	"                           __global uchar*     restrict      result_img,\n",
	"                           __constant const uchar*    pyr_mat __attribute__((max_constant_size(25))),\n",
	"                                   int                       src_width,\n",
	"                                   int                       src_size,\n",
	"                                   int                       result_width)\n",
	"    {\n",
	"        const int result_x = get_global_id(0);\n",
	"        const int result_y = get_global_id(1);\n",
	"        const int wid_x = result_x<<1;\n",
	"        const int wid_y = result_y<<1;\n",
	"        int idx = 0;\n",
	"        int idx1 = (wid_y - 2)*src_width + wid_x;\n",
	"        int sum = 0;\n",
	"    #pragma unroll \n",
	"        for (int i = -2; i < 3; ++i)\n",
	"        {\n",
	"    #pragma unroll \n",
	"           for (int j = -2; j < 3; ++j)\n",
	"           {\n",
	"               sum += src_img[idx1 + j]*pyr_mat[idx];\n",
	"               idx++;\n",
	"           }\n",
	"           idx1 += src_width;\n",
	"        }\n",
	"        result_img[result_y*result_width + result_x] = sum>>8;\n",
	"    }\n",
	"    \n",
	"    __kernel void histogram_adjust(__global uchar*           src_img,\n",
	"                                   int                       src_width,\n",
	"                                   int                       src_size,\n",
	"                                   int                       hist_value)\n",
	"    {\n",
	"        const int wid_x = get_global_id(0);\n",
	"        const int wid_y = get_global_id(1);\n",
	"        int idx = wid_y*src_width + wid_x;\n",
	"        if (src_img[idx] == 0) src_img[idx] = hist_value;\n",
	"    }\n",
	"    \n",
	"    __kernel void affine_transform(__global const uchar*  restrict   src_img,\n",
	"                                   __global uchar*  restrict  result_img,\n",
	"                                   __constant const float*    trans_mat __attribute__((max_constant_size(24))),\n",
	"                                   int                       src_width,\n",
	"                                   int                       src_size)\n",
	"    {\n",
	"        const int wid_x = get_global_id(0);\n",
	"        const int wid_y = get_global_id(1);\n",
	"        uchar pixel = src_img[wid_y*src_width + wid_x];\n",
	"        int2 transCoords = { wid_x*trans_mat[0] + wid_y*trans_mat[1] + trans_mat[2], wid_x*trans_mat[3] + wid_y*trans_mat[4] + trans_mat[5]};\n",
	"        int idx = transCoords.y*src_width + transCoords.x;\n",
	"        if (idx > 0 && idx < src_size)result_img[idx] = pixel;\n",
	"    }\n",
	"    \n",
	" __kernel void sobelDxDy(__global const uchar*      restrict   src_image,\n",
	"                                 __global float*     restrict      result_mag,\n",
	"                                 __global float*     restrict      result_angle,\n",
	"                                 int                      src_width,\n",
	"                                 int                      startX,\n",
	"                                 int                      startY,\n",
	"                                 int                      result_width)\n",
	"    {\n",
	"        const int wid_x = get_global_id(0);\n",
	"        const int wid_y = get_global_id(1);\n",
	"        const int idx = (wid_y + startY) * src_width + wid_x + startX;\n",
	"        const int idx2 = wid_y * result_width + wid_x;\n",
	"        float dx = src_image[idx+1] - src_image[idx - 1];\n",
	"        float dy = src_image[idx+src_width] - src_image[idx - src_width];\n",
	"        result_angle[idx2] = atan2(dy, dx)*57.29577951f;\n",
	"        dx = fabs(dx);\n",
	"        dy = fabs(dy);\n",
	"        result_mag[idx2] = fmax(dx, dy)*0.960433870103f + fmin(dx, dy)*0.397824734759;\n",
	"    \n",
	"    }\n",
	"// The remainder kernel calculates the leftover of matmul operation which couldn't fit into the matmul kernel tile\n",
	"    __kernel void matmul_remainder( __global const float* restrict matrix_a,\n",
	"                                   __global const  float* restrict matrix_b,\n",
	"                                   __global        float* restrict matrix_c,\n",
	"                                                   int    x_rem_start,\n",
	"                                                   int    y_rem_start,\n",
	"                                                   int    result_width,\n",
	"                                                   int    matrix_a_width)\n",
	"    {\n",
	"        const int wid_x = get_global_id(0);\n",
	"        const int wid_y = y_rem_start + get_global_id(1);\n",
	"    \n",
	"        float16 a, a1, a2, a3;\n",
	"        float16 b, b1, b2, b3;\n",
	"        int   b_idx = wid_x << 6;\n",
	"        int   idx = matrix_a_width * wid_y + b_idx;\n",
	"        int   idx2 = wid_y * result_width + wid_x;\n",
	"        b = vload16(0, matrix_b + b_idx);\n",
	"        b1 = vload16(0, matrix_b + b_idx + 16);\n",
	"        b2 = vload16(0, matrix_b + b_idx + 32);\n",
	"        b3 = vload16(0, matrix_b + b_idx + 48);\n",
	"    \n",
	"        a = vload16(0, matrix_a + idx);\n",
	"        a1 = vload16(0, matrix_a + idx + 16);\n",
	"        a2 = vload16(0, matrix_a + idx + 32);\n",
	"        a3 = vload16(0, matrix_a + idx + 48);\n",
	"        matrix_c[idx2] = a.s0*b.s0 + a.s1*b.s1 + a.s2*b.s2 + a.s3*b.s3 + a.s4*b.s4 + a.s5*b.s5 + a.s6*b.s6 + a.s7*b.s7 + a.s8*b.s8 + a.s9*b.s9 + a.sA*b.sA + a.sB*b.sB + a.sC*b.sC + a.sD*b.sD + a.sE*b.sE + a.sF*b.sF + \n",
	"                           a2.s0*b2.s0 + a2.s1*b2.s1 + a2.s2*b2.s2 + a2.s3*b2.s3 + a2.s4*b2.s4 + a2.s5*b2.s5 + a2.s6*b2.s6 + a2.s7*b2.s7 + a2.s8*b2.s8 + a2.s9*b2.s9 + a2.sA*b2.sA + a2.sB*b2.sB + a2.sC*b2.sC + a2.sD*b2.sD + a2.sE*b2.sE + a2.sF*b2.sF + \n",
	"                           a3.s0*b3.s0 + a3.s1*b3.s1 + a3.s2*b3.s2 + a3.s3*b3.s3 + a3.s4*b3.s4 + a3.s5*b3.s5 + a3.s6*b3.s6 + a3.s7*b3.s7 + a3.s8*b3.s8 + a3.s9*b3.s9 + a3.sA*b3.sA + a3.sB*b3.sB + a3.sC*b3.sC + a3.sD*b3.sD + a3.sE*b3.sE + a3.sF*b3.sF + \n",
	"                           a1.s0*b1.s0 + a1.s1*b1.s1 + a1.s2*b1.s2 + a1.s3*b1.s3 + a1.s4*b1.s4 + a1.s5*b1.s5 + a1.s6*b1.s6 + a1.s7*b1.s7 + a1.s8*b1.s8 + a1.s9*b1.s9 + a1.sA*b1.sA + a1.sB*b1.sB + a1.sC*b1.sC + a1.sD*b1.sD + a1.sE*b1.sE + a1.sF*b1.sF;\n",
	"    \n",
	"    }\n",
	"    \n",
	"// The matmul kernel calculates matrix-vector multiplication using 64x64 size tile\n",
	"    __kernel void matmul( __global const  float* restrict matrix_a,\n",
	"                          __global const  float* restrict matrix_b,\n",
	"                          __global        float* restrict matrix_c,\n",
	"                                                   int   x_rem_start,\n",
	"                                                   int   y_rem_start,\n",
	"                                                   int   result_width,\n",
	"                                                   int   matrix_a_width)\n",
	"    {\n",
	"        const int wid_x = get_global_id(0);\n",
	"        const int wid_y = get_global_id(1) << 6;\n",
	"    \n",
	"        float16 a, a1, a2, a3;\n",
	"        float16 b, b1, b2, b3;\n",
	"        int   b_idx = wid_x << 6;\n",
	"        int   idx = matrix_a_width * wid_y + b_idx;\n",
	"        int   idx2 = wid_y * result_width + wid_x;\n",
	"        b = vload16(0, matrix_b + b_idx);\n",
	"        b1 = vload16(0, matrix_b + b_idx + 16);\n",
	"        b2 = vload16(0, matrix_b + b_idx + 32);\n",
	"        b3 = vload16(0, matrix_b + b_idx + 48);\n",
	"    \n",
	"    #pragma unroll \n",
	"        for (int i = 0; i < 64; ++i)\n",
	"        {\n",
	"            a = vload16(0, matrix_a + idx);\n",
	"            a1 = vload16(0, matrix_a + idx + 16);\n",
	"            a2 = vload16(0, matrix_a + idx + 32);\n",
	"            a3 = vload16(0, matrix_a + idx + 48);\n",
	"//                matrix_c[idx2 + result_width*i] = dot(a.s0123, b.s0123) + dot(a.s4567, b.s4567) + dot(a.s89ab, b.s89ab) + dot(a.scdef, b.scdef) + dot(a1.s0123, b1.s0123) + dot(a1.s4567, b1.s4567) + dot(a1.s89ab, b1.s89ab) + dot(a1.scdef, b1.scdef) +\n",
	"//        dot(a2.s0123, b2.s0123) + dot(a2.s4567, b2.s4567) + dot(a2.s89ab, b2.s89ab) + dot(a2.scdef, b2.scdef) + dot(a3.s0123, b3.s0123) + dot(a3.s4567, b3.s4567) + dot(a3.s89ab, b3.s89ab) + dot(a3.scdef, b3.scdef);\n",
	"            matrix_c[idx2 + result_width*i] = a.s0*b.s0 + a.s1*b.s1 + a.s2*b.s2 + a.s3*b.s3 + a.s4*b.s4 + a.s5*b.s5 + a.s6*b.s6 + a.s7*b.s7 + a.s8*b.s8 + a.s9*b.s9 + a.sA*b.sA + a.sB*b.sB + a.sC*b.sC + a.sD*b.sD + a.sE*b.sE + a.sF*b.sF + \n",
	"               a2.s0*b2.s0 + a2.s1*b2.s1 + a2.s2*b2.s2 + a2.s3*b2.s3 + a2.s4*b2.s4 + a2.s5*b2.s5 + a2.s6*b2.s6 + a2.s7*b2.s7 + a2.s8*b2.s8 + a2.s9*b2.s9 + a2.sA*b2.sA + a2.sB*b2.sB + a2.sC*b2.sC + a2.sD*b2.sD + a2.sE*b2.sE + a2.sF*b2.sF + \n",
	"               a3.s0*b3.s0 + a3.s1*b3.s1 + a3.s2*b3.s2 + a3.s3*b3.s3 + a3.s4*b3.s4 + a3.s5*b3.s5 + a3.s6*b3.s6 + a3.s7*b3.s7 + a3.s8*b3.s8 + a3.s9*b3.s9 + a3.sA*b3.sA + a3.sB*b3.sB + a3.sC*b3.sC + a3.sD*b3.sD + a3.sE*b3.sE + a3.sF*b3.sF + \n",
	"               a1.s0*b1.s0 + a1.s1*b1.s1 + a1.s2*b1.s2 + a1.s3*b1.s3 + a1.s4*b1.s4 + a1.s5*b1.s5 + a1.s6*b1.s6 + a1.s7*b1.s7 + a1.s8*b1.s8 + a1.s9*b1.s9 + a1.sA*b1.sA + a1.sB*b1.sB + a1.sC*b1.sC + a1.sD*b1.sD + a1.sE*b1.sE + a1.sF*b1.sF;\n",
	"            idx += matrix_a_width;\n",
	"        }\n",
	"    \n",
	"    }\n",
	"    \n",
	"   __kernel void matmul_reduce(__global const  float   * restrict matrix_a,\n",
	"                                   __global        float * restrict matrix_c,\n",
	"                                                   int    matrix_a_width,\n",
	"                                                   int    step_count)\n",
	"    {\n",
	"        const int wid_y = get_global_id(0);\n",
	"        const int idx = wid_y * matrix_a_width;\n",
	"    \n",
	"        float c = 0.0f;\n",
	"        float16 a;\n",
	"    \n",
	"    #pragma unroll \n",
	"        for (int i = 0; i < step_count; ++i)\n",
	"        {\n",
	"            a = vload16(0, matrix_a + idx + i*16);\n",
	"            c += a.s0 + a.s1 + a.s2 + a.s3 + a.s4 + a.s5 + a.s6 + a.s7 + a.s8 + a.s9 + a.sA + a.sB + a.sC + a.sD + a.sE + a.sF;\n",
	"        }\n",
	"//unfortunately we have to hardcode the remainder here, when the matrix width is not divisible by stepSize\n",
	"//otherwise the overhead of calculating this in a separate kernel is a bit too high\n",
	"        matrix_c[wid_y] = c + matrix_a[idx + 176];\n",
	"    }\n",
	""};


static const size_t CL_EXINOS_SIZE = sizeof(CL_EXINOS) / sizeof(const char *);


static const char *CL_MATRIXMUL[] = { 
	"/*\n",
	" * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
	" *\n",
	" * Please refer to the NVIDIA end user license agreement (EULA) associated\n",
	" * with this source code for terms and conditions that govern your use of\n",
	" * this software. Any use, reproduction, disclosure, or distribution of\n",
	" * this software and related documentation outside the terms of the EULA\n",
	" * is strictly prohibited.\n",
	" *\n",
	" */\n",
	"\n",
	"/* Matrix multiplication: C = A * B.\n",
	" * Device code.\n",
	" */\n",
	"\n",
	"#define AS(i, j) As[j + i * BLOCK_SIZE]\n",
	"#define BS(i, j) Bs[j + i * BLOCK_SIZE]\n",
	"\n",
	"///////////////////////////////////////////////////////////////////////////////\n",
	"//! Matrix multiplication on the device: C = A * B\n",
	"//! uiWA is A's width and uiWB is B's width\n",
	"////////////////////////////////////////////////////////////////////////////////\n",
	"__kernel void\n",
	"matrixMul( __global float* C, __global float* A, __global float* B, \n",
	"	   __local float* As, __local float* Bs, int uiWA, int uiWB, int trueLocalSize1)\n",
	"{\n",
	"    // Block index\n",
	"    int bx = get_group_id(0);\n",
	"    int by = get_group_id(1);\n",
	"\n",
	"    // Thread index\n",
	"    int tx = get_local_id(0);\n",
	"    int ty = get_local_id(1);\n",
	"\n",
	"    // Index of the first sub-matrix of A processed by the block\n",
	"    int aBegin = uiWA * BLOCK_SIZE * by;\n",
	"\n",
	"    // Index of the last sub-matrix of A processed by the block\n",
	"    int aEnd   = aBegin + uiWA - 1;\n",
	"\n",
	"    // Step size used to iterate through the sub-matrices of A\n",
	"    int aStep  = BLOCK_SIZE;\n",
	"\n",
	"    // Index of the first sub-matrix of B processed by the block\n",
	"    int bBegin = BLOCK_SIZE * bx;\n",
	"\n",
	"    // Step size used to iterate through the sub-matrices of B\n",
	"    int bStep  = BLOCK_SIZE * uiWB;\n",
	"\n",
	"    // Csub is used to store the element of the block sub-matrix\n",
	"    // that is computed by the thread\n",
	"    float Csub = 0.0f;\n",
	"\n",
	"    // Loop over all the sub-matrices of A and B\n",
	"    // required to compute the block sub-matrix\n",
	"    for (int a = aBegin, b = bBegin;\n",
	"             a <= aEnd;\n",
	"             a += aStep, b += bStep) {\n",
	"\n",
	"        // Load the matrices from device memory\n",
	"        // to shared memory; each thread loads\n",
	"        // one element of each matrix\n",
	"        AS(ty, tx) = A[a + uiWA * ty + tx];\n",
	"        BS(ty, tx) = B[b + uiWB * ty + tx];\n",
	"	\n",
	"        // Synchronize to make sure the matrices are loaded\n",
	"        barrier(CLK_LOCAL_MEM_FENCE);\n",
	"\n",
	"        // Multiply the two matrices together;\n",
	"        // each thread computes one element\n",
	"        // of the block sub-matrix        \n",
	"        #pragma unroll\n",
	"        for (int k = 0; k < BLOCK_SIZE; ++k)\n",
	"            Csub += AS(ty, k) * BS(k, tx);\n",
	"\n",
	"        // Synchronize to make sure that the preceding\n",
	"        // computation is done before loading two new\n",
	"        // sub-matrices of A and B in the next iteration\n",
	"        barrier(CLK_LOCAL_MEM_FENCE);\n",
	"    }\n",
	"\n",
	"    if (get_global_id(1) < trueLocalSize1)\n",
	"    // Write the block sub-matrix to device memory;\n",
	"    // each thread writes one element\n",
	"    C[get_global_id(1) * get_global_size(0) + get_global_id(0)] = Csub;\n",
	"\n",
	"}\n",
	"\n",
	""};


static const size_t CL_MATRIXMUL_SIZE = sizeof(CL_MATRIXMUL) / sizeof(const char *);


static const char *CL_MATRIXMUL[] = { 
	"/*\n",
	" * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
	" *\n",
	" * Please refer to the NVIDIA end user license agreement (EULA) associated\n",
	" * with this source code for terms and conditions that govern your use of\n",
	" * this software. Any use, reproduction, disclosure, or distribution of\n",
	" * this software and related documentation outside the terms of the EULA\n",
	" * is strictly prohibited.\n",
	" *\n",
	" */\n",
	"\n",
	"/* Matrix multiplication: C = A * B.\n",
	" * Device code.\n",
	" */\n",
	"\n",
	"#define AS(i, j) As[j + i * BLOCK_SIZE]\n",
	"#define BS(i, j) Bs[j + i * BLOCK_SIZE]\n",
	"\n",
	"///////////////////////////////////////////////////////////////////////////////\n",
	"//! Matrix multiplication on the device: C = A * B\n",
	"//! uiWA is A's width and uiWB is B's width\n",
	"////////////////////////////////////////////////////////////////////////////////\n",
	"__kernel void\n",
	"matrixMul( __global float* C, __global float* A, __global float* B, \n",
	"	   __local float* As, __local float* Bs, int uiWA, int uiWB, int trueLocalSize1)\n",
	"{\n",
	"    // Block index\n",
	"    int bx = get_group_id(0);\n",
	"    int by = get_group_id(1);\n",
	"\n",
	"    // Thread index\n",
	"    int tx = get_local_id(0);\n",
	"    int ty = get_local_id(1);\n",
	"\n",
	"    // Index of the first sub-matrix of A processed by the block\n",
	"    int aBegin = uiWA * BLOCK_SIZE * by;\n",
	"\n",
	"    // Index of the last sub-matrix of A processed by the block\n",
	"    int aEnd   = aBegin + uiWA - 1;\n",
	"\n",
	"    // Step size used to iterate through the sub-matrices of A\n",
	"    int aStep  = BLOCK_SIZE;\n",
	"\n",
	"    // Index of the first sub-matrix of B processed by the block\n",
	"    int bBegin = BLOCK_SIZE * bx;\n",
	"\n",
	"    // Step size used to iterate through the sub-matrices of B\n",
	"    int bStep  = BLOCK_SIZE * uiWB;\n",
	"\n",
	"    // Csub is used to store the element of the block sub-matrix\n",
	"    // that is computed by the thread\n",
	"    float Csub = 0.0f;\n",
	"\n",
	"    // Loop over all the sub-matrices of A and B\n",
	"    // required to compute the block sub-matrix\n",
	"    for (int a = aBegin, b = bBegin;\n",
	"             a <= aEnd;\n",
	"             a += aStep, b += bStep) {\n",
	"\n",
	"        // Load the matrices from device memory\n",
	"        // to shared memory; each thread loads\n",
	"        // one element of each matrix\n",
	"        AS(ty, tx) = A[a + uiWA * ty + tx];\n",
	"        BS(ty, tx) = B[b + uiWB * ty + tx];\n",
	"	\n",
	"        // Synchronize to make sure the matrices are loaded\n",
	"        barrier(CLK_LOCAL_MEM_FENCE);\n",
	"\n",
	"        // Multiply the two matrices together;\n",
	"        // each thread computes one element\n",
	"        // of the block sub-matrix        \n",
	"        #pragma unroll\n",
	"        for (int k = 0; k < BLOCK_SIZE; ++k)\n",
	"            Csub += AS(ty, k) * BS(k, tx);\n",
	"\n",
	"        // Synchronize to make sure that the preceding\n",
	"        // computation is done before loading two new\n",
	"        // sub-matrices of A and B in the next iteration\n",
	"        barrier(CLK_LOCAL_MEM_FENCE);\n",
	"    }\n",
	"\n",
	"    if (get_global_id(1) < trueLocalSize1)\n",
	"    // Write the block sub-matrix to device memory;\n",
	"    // each thread writes one element\n",
	"    C[get_global_id(1) * get_global_size(0) + get_global_id(0)] = Csub;\n",
	"\n",
	"}\n",
	"\n",
	""};


static const size_t CL_MATRIXMUL_SIZE = sizeof(CL_MATRIXMUL) / sizeof(const char *);


#endif

/* ###### End AutoGenerated File. ###### */
